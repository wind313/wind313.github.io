[{"title":"ARP协议","url":"/2024/11/23/ARP%E5%8D%8F%E8%AE%AE/","content":"主机A给主机B发送IP数据报文，需要通过ARP（address resolution protocol，地址解析协议）获取下一跳的MAC地址，并将IP报文封装成链路层帧，发送到下一跳上。\n\n\n同一局域网注：以下为同一局域网主机A给主机B发送IP数据报过程，2-5为ARP寻址过程。\n\n主机A检索自己ARP表，发现ARP表中有主机B的IP地址对应的映射条目，提取MAC地址并构造链路层帧发送；若没有，继续以下过程。\n每个网络设备维护一个ARP表，记录其他网络设备的IP地址与MAC地址映射关系，以&lt;IP,MAC,TTL&gt;三元组形式存储，TTL为过期时间，一般为20分钟。\n\n主机A构造一个ARP查询分组，广播到所在局域网中。\nARP分组是一种报文，分为查询分组和响应分组，格式相同，均包含源IP和MAC以及目的IP和MAC。\n查询分组：源IP和MAC为主机A的IP和MAC，目的IP为主机B的IP，目的MAC为FF-FF-FF-FF-FF-FF（广播地址）。\n\n查询分组在局域网内广播，每一个设别收到后检查接收IP是否为自己的IP，如果不是，则丢弃；如果是，则查询分组已经到主机B，继续以下过程。\n\n主机B先把主机A的IP-MAC映射存到自己的ARP表中，然后构造一个ARP响应分组，发送给主机A。\n响应分组：源IP和MAC为主机B的IP和MAC，目的IP和MAC为主机A的IP和MAC。\n\n主机A收到主机B的响应分组，提取出该分组中的源IP和MAC（主机B的IP和MAC），构造映射信息加入到自己的ARP表中。\n\n主机A从ARP表中获取主机B的MAC，将IP数据报封装成链路层帧，发送给主机B。\n\n\n\n不同局域网主机A和主机B所在的子网由一台路由器联通。\n注：路由器的每个接口都有一个IP和MAC，即每个接口都有一个ARP表。\n整个过程分为三个阶段：\n\nIP数据报从主机A发到路由器中主机A所在子网所连接的接口；（相当于统一子网内）\n路由器查询转发表，将IP数据报转发到与主机B所在子网所连接的接口；\n主机B所在子网所连接的接口将IP数据报发送给主机B；（相当于同一子网内）\n\n","categories":["计算机网络"]},{"title":"Redis集群","url":"/2024/11/18/Redis%E9%9B%86%E7%BE%A4/","content":"主从集群主从复制主从复制基于Redis replication（默认使用异步复制），可以通过replicaof（Redis5.0之前是slaveof）命令配置各个节点的主从关系。配置完成后主从节点数据同步会自动进行。\n第一次同步（全量复制）\n从节点（slave）向主节点发送psync命令请求复制，主节点（master）收到psync命令后，使用fullresync命令（全量复制）响应从节点。\npsync包含两个参数：\n\nrunID（redis4.0之后改为replid和replid2）：主服务器runID，第一次同步时值为’?’；\noffset：复制进度，第一次同步时，值为-1；\n\nfullresync返回这两个参数。\n\n主节点执行bgsave命令生成RDB文件（子进程去生成）并发送给从节点，从节点清空当前数据，载入RDB文件。\n这期间的写操作命令写入到replication buffer中。\n\n从节点完成RDB载入后，回复一个确认消息给主节点，主节点将replication buffer里记录的写操作命令发送给从节点，从节点去执行，此时第一次同步就完成了。\n\n\n第一次同步后主节点和从节点会维护一个TCP长连接，主节点通过这个连接将写操作命令发送给从节点，从节点去执行。\n\n当从节点过多时，主节点生成RDB和传输RDB的压力会很大，可以让部分从节点成为其他从节点的主节点去分摊主节点的压力。\n\n增量复制Redis2.8之前如果主从节点在命令同步时网络断开又恢复，从节点就会和主节点需要重新进行一次全量复制。\nRedis2.8开始网络断开恢复后，只把网络断开期间主节点接收到的写操作命令，同步给从节点。\n主节点通过repl_backlog_buffer（复制积压缓冲区，一个环形队列，默认大小1MB，可以自定义）记录从生成RDB文件开始收到的所有写命令，一个主节点只有一个repl_backlog_buffer。\nrepl_backlog_buffer的信息在Replication里，可以通过INFO replication命令查看。\n增量复制过程如下：\n\n从节点恢复网络后，发送psync命令（包含runID和offset）给主节点；\n主节点判断收到的runID和自己的runID是否相等，如果相等，使用continue（增量复制）命令响应从节点；\n主节点将断连期间执行的写命令发给从节点，从节点去执行。\n\n\n以下情况需要全量同步：\n\n从节点缺少的数据不在repl_backlog_buffer中；\n从节点宕机或重启，runID和offset丢失；\n主节点宕机，新选出来的主节点的runID和offset会发生变化。\n\nRedis4.0之后主从切换后仍然可能使用增量复制。\n使用replid和replid2代替runid：\n\n主节点：replid就是自己的id。主从切换之前，replid2为空；主从切换之后，新主节点的replid2是旧主节点（自己之前的主节点）的replid。\n从节点：replid是自己当前的主节点的replid。replid2是旧主节点的replid。\n\n还有两个字段：\n\nmaster_repl_offset：当前的复制偏移量；\nsecond_replid_offset：主从切换前，值为-1，主从切换后，新的主节点的second_replid_offset是旧主节点的复制偏移量。\n\n通过replid和replid2判断主从切换之后，新的主节点和从节点曾经是否属于同一个主库。如果属于同一个主库，可能进行增量复制。\n新主节点同步进度必须比从节点快，并且进度差异不能超过repl_backlog_buffer大小，否则进行全量复制。\nRDB会记录主从复制相关信息（比如replid），用于解决从节点重启后需要全量复制的问题。\n从节点可能读到过期数据\nRedis3.2之前，客户端读从库不会判断数据是否过期，可能返回过期数据。Redis3.2之后，客户端读从库会优先判断数据是否过期，如果过期，从库不会删除，但会返回空数据，避免返回空数据。\n使用EXPIRE和PEXPIRE设置过期时间（执行该命令往后TTL时间过期）时，如果从节点执行命令因为网络等原因延迟，客户端可能读到过期数据。可以使用EXPIREAT和PEXPIREAT（设置过期的时间戳），但主从节点时钟需保持一致。\n\n哨兵哨兵（sentinel，稳定版在Redis2.8之后发布）是Redis的一种特殊运行模式，也是一个节点，不提供读写服务，默认端口26379。\n运行哨兵通过以下命令让Redis以哨兵模式运行：\nredis-sentinel /path/to/sentinel.conf或redis-server /path/to/sentinel.conf --sentinel\n\n建议启动三个以上并且奇数个哨兵协作运行，可以增强容错性（避免网络波动等因素导致的误判）和可用性（一个哨兵失效，其他依然可用）。\n哨兵功能\n监控：监控所有节点（包括自己）状态是否正常；\n故障转移：主节点故障时，自动将一个从节点升级为主节点；\n通知：通知从节点新的主节点连接信息，让它们执行replicaof成为新的主节点的从节点；\n配置提供：客户端连接哨兵，如果故障转移，哨兵会通知新的主节点信息给客户端。\n\n哨兵集群组成哨兵节点之间通过Redis的发布订阅机制互相发现。主从集群中，主节点有一个_sentinel_:hello频道，不同哨兵通过该频道实现互相发现和互相通信。\n哨兵每10秒会向主节点发送INFO命令获取所有从节点列表，根据列表中的连接信息，和每个从节点建立连接并监控从节点。\n\n检测节点下线哨兵每隔1秒会给其他所有节点发送ping命令，其他节点会响应（pong、loading或masterdown），如果没有在规定时间内响应，哨兵就会标记该节点为主观下线。\n哨兵如果认为主观下线的是从节点，不会做什么。如果是主节点，哨兵向其他哨兵发起命令，其他根据自身和该主节点的网络状况，做出赞成或拒绝的响应。当赞同数量达到哨兵配置文件中的quorum配置项设定的值（建议为哨兵个数&#x2F;2+1）后，主节点才会被判定为客观下线。\n\n然后，哨兵集群会选举（Raft算法）出一个leader进行故障转移。\n选举哨兵集群的leader判断主节点下线的哨兵为候选者，候选者向其他哨兵发送命令表明希望成为leader，其他哨兵进行投票。每个哨兵只有一次投票机会，候选者可以把票投给自己，非候选者只能投给其他哨兵。\n候选者拿到半数以上的票并且票数大于等于哨兵配置文件中的quorum值才能成为leader。\n\n故障转移过程1.选举新主节点；\n\n把已下线的从节点和网络不好的从节点过滤掉。\n如果在down-after-milliseconds（主从最大连接超时时间）毫秒内，主从节点没有通过网络联系上，就可以认为主从节点断连了。如果断连次数超过10次，就认为该节点网络不好。\n\n先根据从节点优先级排序。\n可以修改配置文件中的replica-priority（Redis5.0之前叫slave-priority）手动配置slave的优先级。默认100，越小越靠前，但0表示没有选举资格。没有最高的再进行下一步排序。\n\n再根据复制进度排序。\n数据越完整，即与旧主节点数据越接近的越靠前。没有最高的再进行下一步排序。\n\n最后根据runID排序，越小越靠前。\n\n\n2.将从节点指向新主节点；\n通过向从节点发送slaveof命令，让旧主节点的所有从节点指向新主节点。\n3.通知客户端；\n每个哨兵提供发布订阅机制，客户端可以从客户端订阅消息。主从切换完成后，哨兵会向+switch-master频道发布新主节点的IP地址和端口消息。通过订阅发布机制，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控主从节点切换过程中发生的重要事件，有助于了解切换速度。\n4.将旧主节点变为从节点。\n继续监视旧主节点，当旧主节点重新上线时，哨兵集群向它发送slaveof命令，让他成为新主节点的从节点。\n\n切片集群Redis3.0推出官方切片集群解决方案Redis Cluster。\nRedis Cluster优势\n支持动态扩容和缩容\n具备主从复制、故障转移（内置哨兵机制，不用单独部署哨兵集群）等开箱即用功能。\n\nRedis Cluster架构至少3个主节点和三个从节点，即每个主节点有一个从节点。\nRedis Cluster是去中心化的（每个节点使用Gossip协议通信），key找的是hash槽不是节点，一个主节点故障，不会影响其他主节点。\nRedis Cluster分片采用hash槽（hash slot）分区，每一个键值对属于一个hash槽。\n一个Redis Cluster有16384个hash槽，只需要对key计算CRC-16（XMODEM）校验码（16bit的值），并对校验码取模16384，得到的即是key对应的hash槽。\nhash槽分区优点解耦数据与节点之间的关系，提升集群的横向扩展性和容错性。\nhash槽与节点之间的映射hash槽与节点之间的映射有两种方案：\n\n平均分配：创建并初始化Redis Cluster时，会自动将hash槽平均分配到集群节点上。\n\n手动分配：可以使用cluster meet命令手动建立节点间连接建立集群，再使用cluster addslots命令指定每个节点hash槽个数。\n在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n\n\n在任意主节点上执行cluster slots命令可以查看hash槽与节点映射关系。\n移除某个主节点之前，要将该节点hash槽移动到其他节点上，才可以删除，否则报错。\n客户端定位目标节点客户端连接到任意主节点就可以访问Redis Cluster的数据，客户端发送请求时，根据key找到对应hash槽，再查询hash槽和节点的映射关系就可以找到目标节点。如果hash槽是当前节点负责，直接返回结果；否则（当Redis Cluster重新分配hash槽比如扩容缩容时，可能导致客户端缓存的hash槽分配信息有误）返回-MOVED重定向错误，告知客户端该hash槽是哪个节点负责，客户端向目标节点发送请求并更新缓存的hash槽分配信息。\n\n重定向机制重定向机制可以保证Redis Cluster在扩容和缩容期间能正常对外提供服务，分为ASK重定向（临时重定向）和MOVED重定向（永久重定向）。\n\n如果请求的key对应的hash槽还在当前节点，或者在迁移过程中但key还未迁移走，直接响应；\n如果请求的key对应的hash槽在迁移过程中，且key已经迁移走；\n返回ASK（包含新节点信息）；\n客户端收到ASK，会临时重定向（一次性），即向新节点发送一条ASKING命令，下一次需要重新提前发送ASKING命令；\n如果当前请求的key还在导入中但未完全导入，新节点收到ASKING命令后可能会返回TRYAGAIN（重试错误）；\n客户端发送真正需要请求的命令；\nASK重定向不会更新客户端缓存的hash槽分配信息。\n\n\n如果请求的key对应的hash槽迁移完成，返回-MOVED，客户端向新节点请求并更新缓存的hash槽分配信息。\n\n\n节点间的通信Redis Cluster中的各个节点基于Gossip协议进行通信，每个节点维护一份集群的状态信息。\nRedis Cluster的节点之间会互相发送多种Gossip信息：\n\nMEET：在集群的某个节点上执行CLUSTER MEET ip port命令，可以向指定节点发送一个MEET信息，将其添加进集群中成为新节点。\nPING&#x2F;PONG：集群中的节点都会定时向其他节点发送PING，交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态（PFAIL）和已下线状态（FAIL）；\nFAIL：集群中的A节点发现B节点疑似下线，并且在下线报告的有效期限内集群中半数以上节点将B节点标记为疑似下线，A节点就会向集群广播一条FAIL消息，通知其他节点将B标记为已下线。\n……\n\n源码redis&#x2F;src&#x2F;cluster.h at 7.0 · redis&#x2F;redis中定义了所有消息类型和消息结构。\n","categories":["Redis"]},{"title":"Bean的生命周期","url":"/2024/11/18/Bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","content":"实例化容器找到配置文件中的Bean定义，使用反射创建Bean实例。\n属性赋值注入相关属性，例如@Autowired、@Resource、@Value、构造方法或setter方法注入的各种对象和值。\n初始化Aware接口\n如果Bean实现了BeanNameAware接口，调用setBeanName()方法，将Bean名字传入；\n如果Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象；\n如果Bean实现了BeanFactoryAware接口，调用setBeanFactory()方法，传入BeanFactory对象；\n其他Aware接口。\n\nBeanPostProcessor前置处理如果有和加载这个Bean的容器相关的BeanPostProcessor对象，执行postProcessBeforeInitialization()方法。\nInitializingBean接口如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。\ninit-method如果Bean在配置文件中的定义包含init-method属性，执行指定的方法。\nBeanPostProcessor后置处理如果有和加载这个Bean的Spring容器相关的BeanPostProcessor对象，执行postProcessAfterInitialization()方法。\n销毁把 Bean 的销毁方法先记录下来，将来需要销毁 Bean 或者销毁容器的时候，就调用这些方法去释放 Bean 所持有的资源。\n\n如果Bean实现了DisposableBean接口，执行destroy()方法；\n如果Bean在配置文件中定义了destroy-method属性或者使用@PreDestroy注解标记Bean销毁之前执行的方法，执行指定的Bean销毁方法。\n\n","categories":["Spring"]},{"title":"取石子问题","url":"/2024/11/30/%E5%8F%96%E7%9F%B3%E5%AD%90%E9%97%AE%E9%A2%98/","content":"\n\n\n题目描述有n个石头，A和B轮流取，A先手，每次只能取1-m个，拿到最后一个石头的人胜利，谁会赢？\n找规律当1&lt;&#x3D;n&lt;&#x3D;m时，A必赢（直接拿完）；\n当n &#x3D; m+1时，B必赢（A无论拿多少个，B都可以拿完）；\n当n &#x3D; m+x时(2&lt;&#x3D;x&lt;&#x3D;m+1)，A必赢（A拿x-1个，B就处于n&#x3D;m+1先手的局面，B必输，A必赢）；\n当n &#x3D; 2(m+1)时，A必输（A不管拿多少个，B都可以让A处于n&#x3D;m+1先手的局面，A必输）；\n……\n总结当n%(m+1)&#x3D;0时，后手必赢；否则，先手必赢。\n","categories":["常见面试题"]},{"title":"TCP的可靠性","url":"/2024/11/24/TCP%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/","content":"TCP 是通过连接管理、序列号、确认应答、重发机制、流量控制、拥塞控制等机制实现可靠性传输的。\n\n\n重传机制常见的重传机制有：超时重传、快速重传、SACK、D-SACK\n超时重传发送数据时，设置一个定时器，超过指定时间没有收到ACK确认应答报文，就会重发数据。\n数据包丢失和确认应答报文丢失时都会触发超时重传。\nRTT（数据包从发出去到收到ACK的时间）是经常变化的，因为网络是时常变化的，所以RTO（重传超时时间，应该略大于RTT）也应该是动态变化的值。\nTCP采用一些算法：加权移动平均（EWMA）算法、Karn算法，Jacobson算法。这几个算法结合起来根据RTT的变化来估计RTO的值。\nRTO的计算：\n\n采样\n\n采样RTT，进行加权平均，算出一个SRTT（平滑RTT），这个值是不断变化的。\n采样RTT波动范围，避免RTT大的波动很难被发现。\n\n\n第一次计算\n\n使用第一个RTT测量值来初始化SRTT和DevRTT（RTT测量值与SRTT之间的差异）。\nRFC6289（一份关于RTO估算的标准文档） 建议使用以下公式计算RTO：\n\n\n\n后续计算\n使用新的RTT测量值更新SRTT和SevRTT，更新公式包括平滑因子来调整SRTT和DevRTT，再使用上面公式计算新的RTO。\n\n\n\nEWMA：用在 SRTT 和 DevRTT 的计算中，用于平滑 RTT 的波动。\nKarn ：处理重传时的 RTT 测量问题，确保只有在成功接收到 ACK 时才更新 RTT。\nJacobson：将这两者结合，并提出了 RTO 的计算公式，确保 RTO 能够动态适应网络状况。\n\n一个数据包每次重传时间间隔为前一次的2倍（即重传间隔指数递增），如果两次超时，说明网络环境差，不建议频繁发送。\n快速重传快速重传不已时间为驱动，而是以数据驱动重传。\n\n接收方收到1号报文，ACK回2（收到报文的ACK+1）；\n2号报文没有收到，3号报文收到了，ACK回2；\n后面收到报文，ACK继续回2；\n发送方收到三个相同ACK，会在超时之前，重传2号报文；\n接收到收到2号报文，由于3、4、5号报文都收到，ACK回6。\n\n如果2、3号报文都丢失，4、5、6号报文收到，ACK回2，发送方不知道ACK2是哪个报文的ACK（即不知道2之后有没有丢失报文）。为了解决这个问题，有了SACK方法。\nSACK方法SACK（Selective Acknowledgement，选择性确认）需要在ACK的TCP头部加一个SACK字段，将已收到数据的信息发送给发送方，发送方就只带哪些数据收到和哪些没有收到，就可以只重传丢失数据。\n发送方和接收方都要支持SACK才能打开SACK，Linux可以通过net.ipv4.tcp_sack参数打开，Linux2.4之后默认打开。\nDupliacte SACKDuplicate SACK（D-SACK）主要使用SACK告诉发送方哪些数据被重复接收。\n优点：\n\n可以让发送方知道是发送的包丢失还是ACK包丢失；\n可以知道是不是发送方数据包被网络延迟；\n可以知道网络中是不是把发送方的数据包复制。\n\nLinux可以通过net.ipv4.tcp_dsack参数开启，Linux2.4后默认打开。\n流量控制流量控制就是发送方根据接收方的实际接收能力控制发送的数据量，TCP 利用滑动窗口实现流量控制。\n滑动窗口窗口实际上是操作系统开辟的一个缓存空间，发送方在等到ACK返回前，必须在缓冲区保留已发送的数据，只有按期收到ACK，才可以从缓存区清除。窗口大小就是无需等待确认应答可以继续发送数据的最大值。\nTCP头里有一个Window（窗口大小）字段，接收方通过这个字段告诉发送端自己还有多少缓存区可以接受数据。\n如果接收方资源紧张，操作系统可能直接减少接收缓冲区大小，发送方还不知道接收窗口收缩，发送数据大小超过接收窗口，数据包会丢失，所以TCP规定先收缩窗口，在减少缓存，就可以防止这种情况发生。\n发送方滑动窗口分成四个部分：\n\n已发送并受到ACK的数据；\n已发送未收到ACK的数据；\n未发送但总大小在接收方处理范围内；\n未发送但总大小超过接收方处理范围。\n\n程序使用窗口大小和三个指针（两个绝对指针，一个相对指针）跟踪四个部分：\n\nSND.WND：发送窗口的大小（由接收方指定）；\nSND.UNA(Send Unacknowleged)：绝对指针，指向已发送但未收到ACK（上面第二部分）的第一个字节的序列号；\nSND.NEXT：绝对指针，指向未发送但可发送范围（上面第三部分）的第一个字节的序列号；\n相对指针，指向第四部分的第一个字节，需要SND.YNA指针加上SND.WND大小的偏移量。\n\n可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）。\n接收方滑动窗口分为三个部分：\n\n已接收并确认的数据（等待应用程序读取）；\n未收到数据但可以接收的数据；\n未收到数据并不可以接受的数据。\n\n使用两个指针划分：\n\nRCV.WND：接收窗口大小，回通知给发送发；\nRCV.NXT：指针，指向期望收到的下一个数据字节的序列号，也就是第二部分的第一字节；\n相对指针，指向第三部分的第一个字节，需要RCV.NXT指针加上RCV.WND大小的偏移量。\n\n接收窗口约等于发送窗口大小，不完全相等。因为接收窗口大小不是一成不变的，而且是通过TCP报文告诉发送方的，传输过程存在延时。\n窗口关闭窗口关闭就是窗口变为0时，发送方不会发送数据，直到窗口变为非0为止。\n接收方除了收到数据包会响应ack，接收窗口大小发生显著变化也可以发送一个窗口更新的ACK。\n如果接收方处理完数据，接收窗口变为非0，就会通过ACK报文通知发送方窗口大小，如果该ACK丢失，就会导致发送方一直等待接收方的非0窗口通知，接收方也一直等待发送方的数据，会造成死锁。\nTCP为每个连接设置一个定时器，只要一方收到对方0窗口通知，就启动定时器，如果超时，就会发送Window probe（窗口探测）报文，接收方确认这个报文时，给出自己接收窗口大小。如果接收窗口还是0，重新启动计时器。窗口探测次数一般3次，每次30-60秒，3次后还是0，就会RST报文中断连接。（不同的TCP实现可能不一样）\n糊涂窗口综合症糊涂窗口综合症就是接收方腾出几个字节并告诉发送方现在有几个字节的窗口，发送方义无反顾发送这几个字节。TCP+IP头有40个字节，发送四十几个字节只为了传输几个字节，不划算。\n解决方式：\n\n接收方不通知小窗口：窗口大小小于min（MSS，缓存空间/2）时，向发送方通知窗口为0；\n发送方避免发送小数据：Nagle算法，只有满足以下任一条件，才可以发送数据：\n窗口大小&gt;=MSS&amp;&amp;数据大小&gt;=MSS；\n收到之前发送数据的ack。\n\n\n\n以上两个结合才能避免糊涂窗口综合症，Nagle算法默认是打开的，对于一些小数据包交互的场景（比如telnet、ssh），需要关闭Nagle算法。可以在Socket设置TCP_NODELAY选项关闭该算法（没有全局参数）。\n拥塞控制拥塞控制就是根据当前网络状况调整发送数据速度。\ncwnd（拥塞窗口）变化规则：\n\n网络中没有阻塞，cwnd增大；\n网络中出现阻塞（没有在规定时间内收到ACK），cwnd减小。\n\n拥塞控制有四个算法：慢启动、拥塞避免、拥塞发生、快速恢复。\n慢启动发送方每收到一个ACK，cwnd就会+1。\n\n初始化cwnd为1（假设为1，Linux可以使用ss -nli命令查看每个TCP连接的cwnd初始值），开始发送数据包，发包个数为1；\n收到ACK，此时cwnd = cwnd+1=2，发包个数为2；\n收到2个ACK，cwnd = cwnd+2=4，发包个数为4；\n收到4个ACK，cwnd = cwnd+4=8，发包个数为8；\n\n……\n慢启动发包个数指数型增长，当cwnd&lt;ssthresh（slow start threshold，慢启动门限，一般为65535字节）时，使用慢启动，否则使用拥塞避免。\n拥塞避免发送方每收到一个ACK，cwnd = cwnd+1/cwnd。\n假定ssthresh为8，此时cwnd为8：发送方收到8个ACK，每个+1/8，一共+1，即cwnd=cwnd+1=9。\n拥塞避免发包个数是线性增长，cwnd增长过程中，网络会进入阻塞状况，出现丢包，触发重传机制，就会进入拥塞发生。\n拥塞发生超时重传和快速重传的拥塞发送算法是不同的。\n\n超时重传\nssthresh=cwnd/2；\ncwnd恢复为初始值。\n重新开始慢启动。\n\n\n快速重传\ncwnd = cwnd/2；\nssthresh = cwnd；\n进入快速恢复\n\n\n\n快速恢复\ncwnd = ssthresh +3（收到3个ACK）；\n重传丢失数据包；\n如果收到重复ACK，cwnd+1；\n如果收到新数据ACK，把cwnd设置为ssthresh值，因为ACK确认了新数据，说明duplicate ACK都收到，恢复过程结束，恢复到之前状态，进入拥塞避免。\n\n","categories":["计算机网络"]},{"title":"类和对象生命周期","url":"/2024/11/17/%E7%B1%BB%E5%92%8C%E5%AF%B9%E8%B1%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","content":"类的生命周期加载通过全限定名，获取字节码文件的字节流，将字节流所代表的静态存储结构，转化为方法区运行时数据结构，并生成一个Class类型的对象，作为方法区中这个类的访问入口。\n由双亲委派机制决定使用哪个类加载器来加载（可以打破双亲委派机制）。\n加载与连接的部分动作是交叉进行的，加载阶段未结束，连接阶段可能就已开始（如字节码文件格式验证）。\n连接\n验证确保字节流包含的信息符合当前JVM要求以及该类不会危害JVM。包括文件格式验证（字节码文件格式检查）、元数据验证（字节码语义检查）、字节码验证（程序语义检查）、符号引用验证（类正确性检查）。\n验证很有必要，但不是必须执行。如果全部代码都已被反复使用和验证，可以使用-Xverify:none参数关闭大部分类验证措施，缩短类加载时间。但Java9开始，验证过程变得更加高效，Java11之后，官方不推荐使用-Xverify:none 参数来关闭验证。\n\n准备为静态变量分配内存并设置初始值（除了被final修饰的变量，因为其在编译时就已经设置）。\nJava7之前静态变量在永久代中分配，Java7（将方法区的实现改为元空间）及之后静态变量与Class对象一起放在堆中。\n\n解析将常量池中符号引用替换为直接引用（得到类或者字段、方法在内存中的指针或者偏移量）。\n针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用。\n深入理解Java虚拟机中对符号引用以及直接引用的解释如下：\n\n\n\n初始化执行类的初始化方法（即clinit()方法，编译后自动生成）。\nclinit()是带锁线程安全，在多线程环境下进行类初始化的话可能会引起多个线程阻塞，这种阻塞很难被发现。\n只有以下六种情况，必须对类初始化：\n\nnew（创建该类实例对象）、getstatic（访问该类静态变量，除常量）、putstatic（对该类静态变量赋值）、invokestatic（调用该类类静态方法）；\n使用 java.lang.reflect对该类反射调用时；\n初始化该类的子类时；\n主类（包含main方法的类）；\n使用MethodHandle和VarHandle（轻量级的反射调用）时，必须先使用findStaticVarHandle初始化要调用的类；\nJava8（接口中可以定义defaut修饰的方法）及之后，接口中定义了default修饰的方法时，如果要初始化它的实现类，要先初始化该接口。\n\n使用使用类或者创建对象。\n卸载\n类的所有实例被回收；\n加载该类的类加载器实例被回收；\n类没有在其他任何地方被引用。\n\n满足以上情况，该类会被卸载。\n对象的生命周期类加载检查检查new指令的参数能否在常量池中定位到该类的符号引用，并检查该符号引用对象的类是否被初始化。如果没有，要先加载相应的类。\n分配内存内存分配方式由Java堆是否规整（是否有内存碎片）决定，堆是否规整由垃圾收集器的回收算法决定，标记整理和复制时规整的，标记清除不是规整的。\n两种方式\n指针碰撞（内存规整：Serial、ParNew、Parallel、G1）：\n用过的内存全部整合到一边，没有用过的放在另一边，中间有一个分界指针，需要向着没用过的内存方向将该指针移动对象内存大小位置。\n\n空闲列表（内存不规整：CMS）：\n维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例。\n\n\n并发问题为每一个线程预先在 Eden 区分配一块儿内存（TLAB），JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS+失败重试 进行内存分配。\n初始化零值将分配到的内存空间都初始化为零值（不包括对象头），保证了对象的属性在 Java 代码中可以不赋初始值就直接使用。\n设置对象头对象头由Mark Word（主要部分）和Class Pointer组成。\nMark Word\n对象哈希码：在生命周期中可能改变，尤其在锁状态改变时；\n锁信息：无锁状态（没有锁信息）、偏向锁（包含偏向线程ID）、轻量级锁（包含锁的指针，如自旋锁的记录）、重量级锁（包含指向操作系统的线程调度信息，通常是一个指针）；\nGC信息：对象年龄以及分代信息。\n\nClass Pointerr指向对象的类元数据，包含对象所属类的Class对象引用。Class对象存储了与类相关的结构信息，如字段、方法、父类等。\n执行init方法对虚拟机来说，对象已经产生了，从Java程序来说，创建才开始。执行 new 指令之后会接着执行init方法（构造方法）。\n使用通过引用访问对象的属性和方法，在程序运行过程中被不断使用。\n销毁垃圾回收器会在适当的时候检测并回收不再被引用的对象，释放对象占用的内存空间，完成对象的销毁过程。\n","categories":["JVM"]},{"title":"计算机如何存储声音","url":"/2025/05/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E5%A3%B0%E9%9F%B3/","content":"最近在实习中接触到了裁剪和拼接wav音频的需求，对pcm编码和wav文件有了初步了解。\n\n\n编码格式和文件格式编码格式和文件格式是两个不同的概念。如果把音频文件比作食品罐头，那么编码格式就好比罐头里的食品本身。它是新鲜未加工的食材，还是经过压缩脱水处理的食品？而文件格式则像是罐头的包装，是铁罐、玻璃罐还是真空袋，以及标签上写的内容。\n我们常见的音频文件后缀.mp3属于文件格式，它的编码格式一般是mp3。不过，有些特殊情况可能会混用编码格式和文件格式。今天，我们来聊聊wav文件。\nwav文件由文件头和音频数据组成。在wav文件中，音频数据最常使用的编码格式是pcm。pcm是一种无损编码，它没有使用任何算法对音频数据的空间进行压缩。这就像是新鲜未加工的食品，保留了音频最原始、最完整的状态。因此，pcm编码格式也是最直接、最容易理解的音频编码格式。\npcm编码格式pcm音频数据由一个个帧组成，裁剪和拼接pcm音频数据都需要以帧为基本单位，否则就会损坏音频。而帧具体是什么？\n一段声音实际上是连续的，pcm将声音进行采样变成一个个离散的采样点，然后对每个采样点进行量化，最后编码成二进制码。\n\n所以pcm有几个重要基本参数：采样率、采样位数。采样率就是采样的频率，常见的是16kHz，44.1kHz，48kHz；采样位数就是每个采样点使用几位进行存储，常见的有16位（2字节）、24位（2.5字节）。除此之外，还有一个重要参数——声道数，单路音频只有一个声道，而立体声包含左右两个声道。\npcm音频数据的一个帧由每个声道的一个采样点组成。每个帧的大小&#x3D;采样位数*声道数，每秒的帧数&#x3D;采样率&#x2F;声道数。所以只要知道这三个重要参数，就可以根据音频数据大小计算出来音频时间长度，反之也可以计算。\n\nwav文件格式由pcm编码的wav文件的文件头由44个字节（其他编码格式或者存储作者等信息可能会更长）组成：\n\n\n0-3（char[4]）：固定为 &quot;RIFF&quot;，不用关注是什么意思\n\n4-7（uint32）：从下一字段到文件尾的长度，即文件总长度-8\n\n8-11（char[4]）：固定为 &quot;WAVE&quot;，wav文件标识\n\n12-15（char[4]）：固定为&quot;fmt &quot;，mt子块标识\n\n16-19（ uint32）：fmt子块长度，基础pcm编码格式固定为16，其他编码格式或者存储作者等信息可能会更长\n\nfmt子块：\n20-21（ uint16）：编码格式，1为pcm\n22-23（uint16）：声道数\n24-27（uint32）：采样率\n28-31（uint32）：每秒字节数\n32-33（uint16）：每帧字节数\n34-35（uint16）：采样位数\n\n36-39（char[4]）：固定为&quot;data&quot;，数据块标识\n\n40-43（ uint32）：数据块长度\n\n\n总结wav文件由文件头和音频数据组成：\n\n","categories":["音频"]},{"title":"周期性定时器总不准？固定延迟vs固定速率","url":"/2025/06/28/%E5%91%A8%E6%9C%9F%E6%80%A7%E5%AE%9A%E6%97%B6%E5%99%A8%E6%80%BB%E4%B8%8D%E5%87%86%EF%BC%9F%E5%9B%BA%E5%AE%9A%E5%BB%B6%E8%BF%9Fvs%E5%9B%BA%E5%AE%9A%E9%80%9F%E7%8E%87/","content":"最近在做一个实时音频处理的项目，其中有个关键需求：音频片段需要按照 10ms 的间隔采集并推送给RTC模块。按常理计算，1 秒应该正好推送 100 个包（1000ms &#x2F; 10ms），这样才能保证音频播放流畅无卡顿。但实际测试时，每秒收到的音频包总是少那么一两个，有时候是 98 个，有时候是 99 个。\n\n\n问题排查排查过程中，我给每次发送的音频包打上时间戳日志，发现了关键问题：连续两条日志的时间差始终在大约10.1ms左右，按此计算，1000ms&#x2F;10.1ms  &#x3D; 99.010，自然只能发 99 个包。\n[2025-06-25 09:47:13.256892] 发送音频包，序号：1[2025-06-25 09:47:13.267015] 发送音频包，序号：2[2025-06-25 09:47:13.277138] 发送音频包，序号：3[2025-06-25 09:47:13.287261] 发送音频包，序号：4[2025-06-25 09:47:13.297384] 发送音频包，序号：5[2025-06-25 09:47:13.307507] 发送音频包，序号：6[2025-06-25 09:47:13.317630] 发送音频包，序号：7[2025-06-25 09:47:13.327753] 发送音频包，序号：8[2025-06-25 09:47:13.337876] 发送音频包，序号：9[2025-06-25 09:47:13.347999] 发送音频包，序号：10\n\n带着这个发现，我查看定时器源码，发现其核心逻辑是每次执行时都以 “now（本次实际执行时间）+10ms”作为下次执行时间。如果任务执行时间本身有微小误差或延迟，比如 0.1ms，就会导致实际间隔变成 10.1ms，即误差会不断累积。\n// 伪代码// 固定延迟定时器实现void scheduleWithFixedDelay(std::function&lt;void()&gt; task, int intervalMs) &#123;    // 启动定时器线程    std::thread([task, intervalMs]() &#123;        while (true) &#123;        \t// 计算下次执行时间：以上次任务结束时间为基准            auto now = std::chrono::steady_clock::now();            auto nextRun = now + std::chrono::milliseconds(intervalMs);            // 执行任务（发送音频包）            task();            // 等待到下次执行时间            std::this_thread::sleep_until(nextRun);        &#125;    &#125;).detach();&#125;\n\n问题分析通过查阅资料，了解到这属于固定延迟定时器，修改为固定速率定时器即可解决。\n固定延迟与固定速率定时器的核心差异就在于下次执行时间的计算方式。固定速率定时器的下次执行时间是“本次计划执行时间+间隔时间”，不会因为实际执行时间的误差或延迟对后续执行时间有影响。\n解决方案针对这个问题，解决方案是修改定时器逻辑实现固定速率。具体来说，就是保存每次计划执行时间，让下次计划执行时间等于“本次计划执行时间+固定间隔 10ms”，确保间隔稳定。修改后，日志显示每次发送间隔严格稳定在 10ms，实时通信模块也反馈每秒稳定接收 100 个音频包，问题得到彻底解决。\n[2025-06-25 14:23:08.762154] 发送音频包，序号：1[2025-06-25 14:23:08.772158] 发送音频包，序号：2[2025-06-25 14:23:08.782156] 发送音频包，序号：3[2025-06-25 14:23:08.792153] 发送音频包，序号：4[2025-06-25 14:23:08.802155] 发送音频包，序号：5[2025-06-25 14:23:08.812157] 发送音频包，序号：6[2025-06-25 14:23:08.822152] 发送音频包，序号：7[2025-06-25 14:23:08.832154] 发送音频包，序号：8[2025-06-25 14:23:08.842156] 发送音频包，序号：9[2025-06-25 14:23:08.852155] 发送音频包，序号：10\n\n// 伪代码// 固定速率定时器实现void scheduleAtFixedRate(std::function&lt;void()&gt; task, int intervalMs) &#123;    // 记录上次计划执行时间（初始为当前时间）    auto lastScheduledTime = std::chrono::steady_clock::now();        // 启动定时器线程    std::thread([task, intervalMs, lastScheduledTime]() mutable &#123;        while (true) &#123;            // 执行任务（发送音频包）            task();                        // 计算下次计划时间：以上次计划时间为基准            lastScheduledTime += std::chrono::milliseconds(intervalMs);                        // 等待到下次执行时间（如果任务执行超时则立即执行）            auto now = std::chrono::steady_clock::now();            if (lastScheduledTime &gt; now) &#123;                std::this_thread::sleep_until(lastScheduledTime);            &#125;        &#125;    &#125;).detach();&#125;\n\n总结没有万能的技术，只有合适的选择。固定延迟适合任务执行完毕后再等一段时间的场景（如定时备份，若上次没完成，下次可延后），固定速率更适合按刚性节奏执行的场景（如音视频、动画、高频采集）。\n","categories":["异常排查"]},{"title":"java线程池处理任务核心逻辑（源码级分析）","url":"/2025/09/04/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91%EF%BC%88%E6%BA%90%E7%A0%81%E7%BA%A7%E5%88%86%E6%9E%90%EF%BC%89/","content":"线程池是Java 并发编程中提高资源利用率和程序性能的核心组件，也是Java程序员在面试中经常被问到的问题。本文通过JDK的十几行源代码，分析线程池处理任务的完整流程。\n\n\n源代码地址java&#x2F;util&#x2F;concurrent&#x2F;ThreadPoolExecutor.java\npublic void execute(Runnable command)        1332行\n通过对比 JDK7、JDK8、JDK17 和 JDK25 的源码发现，ThreadPoolExecutor.execute()的源代码始终没有丝毫改动。跨越十余年版本迭代的稳定性，印证了其设计的前瞻性。\n源代码public void execute(Runnable command) &#123;        // 任务不能为null，否则抛出异常    if (command == null) &#123;        throw new NullPointerException(&quot;&quot;);    &#125;            // 获取线程池当前的control值（该值高3位为线程池状态，低29位为线程数量）    int c = ctl.get();            // 第一步：如果当前线程数少于核心线程数，直接新建核心线程执行任务    if (workerCountOf(c) &lt; corePoolSize) &#123;        // 尝试创建核心线程，成功则直接返回        // addWorker参数说明：        //   - 第一个参数：新线程启动后执行的首个任务        //   - 第二个参数：true表示核心线程        if (addWorker(command, true)) &#123;            return;        &#125;        // 创建失败，重新获取最新状态（可能被其他线程抢先创建了）        c = ctl.get();    &#125;            // 第二步：核心线程已满，尝试把任务放进队列等待    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;        // 再次检查状态（防止刚入队线程池就关闭了）        int recheck = ctl.get();                // 线程池已停止，从队列移除任务并拒绝        if (!isRunning(recheck) &amp;&amp; remove(command)) &#123;            reject(command);        &#125;        // 所有线程都已销毁，新建非核心线程处理队列任务（极端情况）        else if (workerCountOf(recheck) == 0) &#123;            addWorker(null, false);        &#125;    &#125;            // 第三步：队列已满，尝试创建非核心线程    // 若创建失败（已达最大线程数），则拒绝任务    else if (!addWorker(command, false)) &#123;        reject(command);    &#125;&#125;\n\n官方注释/* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task.  The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#x27;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread.  If it fails, we know we are shut down or saturated * and so reject the task. */\n\n流程图\n思考为什么有核心线程数，还要有最大线程数？非核心线程是线程池应对流量峰值的 “弹性力量”，在核心线程和队列都饱和时临时扩容，任务压力减轻后会根据keepAliveTime自动销毁，避免资源浪费。\n","categories":["Java并发"]},{"title":"HashMap源码分析","url":"/2025/09/08/HashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","content":"HashMap 是 Java 开发中高频使用的数据结构，也是面试重点考察对象。本文通过 JDK 源码中 put 方法和resize方法的核心逻辑，分析 HashMap存数据和扩容的完整流程。\n\n\n源代码地址java&#x2F;util&#x2F;HashMap.java\npublic V put(K key, V value)    610行\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)    624行\nfinal Node&lt;K,V&gt;[] resize()     676行\n本文主要分析JDK8的HashMap。\n源代码默认值static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;    //初始容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;           //最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f;        //负载因子static final int TREEIFY_THRESHOLD = 8;                //树化阈值（单个桶元素数量）static final int UNTREEIFY_THRESHOLD = 6;              //从树转回链表的阈值static final int MIN_TREEIFY_CAPACITY = 64;            //树化最小容量（整个map容量）\n\n成员变量//键值对数组transient Node&lt;K,V&gt;[] table;//键值对集合视图，for-each本质上就是操作这个视图transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //此HashMap中Key-Value键值对数量transient int size;//此Map进行过结构修改的次数（结构修改：元素数量发生改变），相当于版本号，用于迭代器，也是迭代器内可以安全remove的原因。transient int modCount;//扩容阈值（容量 * 负载因子）int threshold;//负载因子final float loadFactor;                    \n\nput方法public V put(K key, V value) &#123;    //方法内部直接调用了putVal方法    return putVal(hash(key), key, value, false, true);&#125;\n\nputVal方法// 参数说明：// hash: key的哈希值// onlyIfAbsent: false则覆盖已有key的值；true则仅在key不存在时插入final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &#123;    Node&lt;K,V&gt;[] tab;  // 哈希表数组    Node&lt;K,V&gt; p;      // 当前桶的头节点    int n, i;         // n=哈希表长度；i=计算出的桶索引    // 1. 哈希表未初始化则先初始化    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;    // 2. 计算桶索引，若桶为空则直接插入新节点    // 由于n为2的幂，(n - 1) &amp; hash等价于hash % n，但位运算效率更高    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);    // 3. 桶不为空，处理哈希冲突    else &#123;        Node&lt;K,V&gt; e;  // 记录已存在的key对应节点        K k;        // 3.1 头节点就是目标key（哈希和key都匹配）        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        // 3.2 头节点是红黑树节点，调用树插入逻辑        else if (p instanceof TreeNode)            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);        // 3.3 遍历链表查找        else &#123;            for (int binCount = 0; ; ++binCount) &#123;                // 3.3.1 遍历到尾部，插入新节点                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    // 链表长度达8时转为红黑树（binCount从0开始）                    if (binCount &gt;= TREEIFY_THRESHOLD - 1)                        treeifyBin(tab, hash);                    break;                &#125;                // 3.3.2 找到匹配的key，退出循环                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;  // 移动到下一个节点            &#125;        &#125;        // 4. 找到已有key，根据onlyIfAbsent决定是否覆盖值        if (e != null) &#123;            V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);  // LinkedHashMap维护访问顺序,HashMap的该方法为空方法            return oldValue;     // 返回旧值        &#125;    &#125;    // 5. 新节点插入后处理    ++modCount;  // 修改计数（用于迭代器快速失败）    // 元素数超过阈值则扩容    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);  // LinkedHashMap的LRU驱逐,HashMap的该方法为空方法    return null;  // 无旧值返回null&#125;\n\nresize方法final Node&lt;K,V&gt;[] resize() &#123;    Node&lt;K,V&gt;[] oldTab = table;       // 旧哈希表    int oldCap = (oldTab == null) ? 0 : oldTab.length;  // 旧容量    int oldThr = threshold;           // 旧扩容阈值    int newCap = 0, newThr = 0;       // 新容量和阈值    // 情况1：旧表已初始化    if (oldCap &gt; 0) &#123;        if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;  // 已达最大容量            threshold = Integer.MAX_VALUE;            return oldTab;        &#125;        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)             newThr = oldThr &lt;&lt; 1;  // 容量和阈值翻倍    &#125;    // 情况2：旧表未初始化但有阈值（构造时指定容量）    else if (oldThr &gt; 0)         newCap = oldThr;  // 阈值作为初始容量（已处理为2的幂）    // 情况3：使用默认参数构造    else &#123;        newCap = DEFAULT_INITIAL_CAPACITY;     // 默认初始容量16        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    // 默认阈值16*0.75       &#125;    // 计算新阈值（情况2未计算时）    if (newThr == 0) &#123;        newThr = (newCap &lt; MAXIMUM_CAPACITY) ?                  (int)(newCap * loadFactor) : Integer.MAX_VALUE;    &#125;    threshold = newThr;  // 更新阈值    // 创建新哈希表    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];    table = newTab;    // 迁移旧表数据到新表    if (oldTab != null) &#123;        for (int j = 0; j &lt; oldCap; j++) &#123;            Node&lt;K,V&gt; e = oldTab[j];            if (e != null) &#123;                oldTab[j] = null;  // 释放旧引用                // 子情况1：桶中只有一个节点                if (e.next == null)                    newTab[e.hash &amp; (newCap - 1)] = e;                // 子情况2：桶中是红黑树                else if (e instanceof TreeNode)                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);                // 子情况3：桶中是链表，拆分为两个子链表                else &#123;                    Node&lt;K,V&gt; loHead = null, loTail = null;  // 留在原位置的链表                    Node&lt;K,V&gt; hiHead = null, hiTail = null;  // 迁移到新位置的链表                    Node&lt;K,V&gt; next;                    do &#123;                        next = e.next;                        // 用哈希值与旧容量判断位置                        if ((e.hash &amp; oldCap) == 0) &#123;                            if (loTail == null) loHead = e;                            else loTail.next = e;                            loTail = e;                        &#125; else &#123;                            if (hiTail == null) hiHead = e;                            else hiTail.next = e;                            hiTail = e;                        &#125;                    &#125; while ((e = next) != null);                    // 放置低位链表到原位置                    if (loTail != null) &#123;                        loTail.next = null;                        newTab[j] = loHead;                    &#125;                    // 放置高位链表到新位置（j+oldCap）                    if (hiTail != null) &#123;                        hiTail.next = null;                        newTab[j + oldCap] = hiHead;                    &#125;                &#125;            &#125;        &#125;    &#125;    return newTab;&#125;\n\n流程图put方法\nresize方法\n思考为什么重写equals()时必须重写hashCode() ?如果只重写equals()而不重写hashCode()，会导致两个内容相同的对象，由于默认的hashCode()方法（基于对象的内存地址生成哈希值），会生成不同的哈希值。当把这两个对象存入HashMap或HashSet时，集合会认为它们是不同的对象，从而可能将内容相同的对象多次存储，破坏了集合 “不存储重复元素”（HashSet）或 “键唯一”（HashMap）的特性。\n为什么HashMap中容量是2的幂？主要是基于位运算的高效性，以及对哈希桶索引计算、扩容操作的优化。\n（1）当n为2的幂时，(n - 1) &amp; hash等价于hash % n，计算哈希桶索引可使用位运算(n - 1) &amp; hash；\n（2）扩容时可以 使用newCap = oldCap &lt;&lt; 1 来实现容量翻倍；\n（3）当n为2的幂时，扩容时可以根据(e.hash &amp; oldCap) == 0判断key放到原位置j还是新位置oldCap+j。\nHashMap 扩容后，原有 key 在新数组中如何分布？等价于使用hash值重新对新容量取余，不过使用了位运算+加法：\n只需判断元素哈希值中与 oldCap 最高位对应的那一位（oldCap是2的幂，所以最高位是1，其余位为0，直接使用与运算即可判断）\n（1）若(e.hash &amp; oldCap) == 0，说明该位为 0，元素在新数组中仍位于原下标 j；\n（2）若(e.hash &amp; oldCap) != 0，说明该位为 1，元素在新数组中位于新下标j + oldCap。\n","categories":["Java集合"]}]